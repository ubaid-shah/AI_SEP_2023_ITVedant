{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbd660b62cc616efa33651beedc49b86045b784d"
   },
   "source": [
    "## <font size=5> <strong> Predicting presence of Heart Disease using Machine Learning  </strong> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e41ea25bec5928203cec544d0413fecd4b4e5555"
   },
   "source": [
    "## Importing essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "f571f7e57c828d45fe55f6136fe8c2e796f74d4e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44e71221837f6fa60edc2c83b7492ddb019cc1cd"
   },
   "source": [
    "## Importing and understanding our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "2a1a1dae64ae3c934849b2b918bc7d68cd59e3f6"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "86353d54a331dbf55a63874402cf13e2a72c3750",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0a2396061d262bee451e61dd51be84d0bd1ac9d0",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c31619815cb0dae5586985671fdc21110b39a821",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "718b82039841c137ab7e08a6e79e264643134642",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "99d7182ca186d37f63b1fc433fe74ad5e2bc7d2f"
   },
   "outputs": [],
   "source": [
    "###Luckily, we have no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1c95f2180e264978c85703ece34898dab4d522b"
   },
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "829fcda5b63e1b9f7ecb7762e8ca617166533aca"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = dataset.drop(\"target\",axis=1)\n",
    "target = dataset[\"target\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7a74842015c2f193d16caa4fa25e2c4cbf1940f8",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "1f777652df4521deb877dac4d5d635d8cd35b279",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "028c968a076840657faf7dbc3bfee9fe7b5ca45a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "eb6857dfc18da52dae38bec95d20106f39136e61",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b4f28488a92917f26e9876c1880295ec9c077ed"
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "fe363c1be8335a48a4444660db5fa6bd0a24b71a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "afa6b322cbc225f3353bd295aea24fe5fbbb78fe"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "9aea2f597203ccf38cd0d67ae58bff6e163dea1c"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "58fb833d1c74355ebdafe926968632942f377421",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "ee4cba838316adf863f8daf131d36a970d36b839",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 86.34 %\n"
     ]
    }
   ],
   "source": [
    "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e224ab23f275a3a56cdba6a9ccfddbd6a4d3b4fd"
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "727b391ad6d86468a96e93dc645ade6e2da4048e"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "650f1baa7db466923626c707408319fa29f22d10"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=13))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                154       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166\n",
      "Trainable params: 166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "dde4e50b5c4c24c73b03133fc7c90bf663fd6d82",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 21.3032 - accuracy: 0.5195\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.8967 - accuracy: 0.6024\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.3589 - accuracy: 0.6110\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 6.9573 - accuracy: 0.6122\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 6.5755 - accuracy: 0.6220\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 6.1579 - accuracy: 0.6110\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 5.7354 - accuracy: 0.6171\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 5.3801 - accuracy: 0.6195\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 4.8908 - accuracy: 0.6220\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4.4931 - accuracy: 0.6256\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4.0781 - accuracy: 0.6354\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.6794 - accuracy: 0.6439\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.2939 - accuracy: 0.6512\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2.9018 - accuracy: 0.6573\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2.5409 - accuracy: 0.6695\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2.2088 - accuracy: 0.6646\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.8552 - accuracy: 0.6829\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.5692 - accuracy: 0.6927\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.3350 - accuracy: 0.7024\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.1291 - accuracy: 0.7366\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.7256\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.7317\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8041 - accuracy: 0.7354\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7549\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7488\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.7585\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7805\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7866\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7890\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8000\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7951\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7976\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8122\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8183\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8000\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8134\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8024\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8000\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8073\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8000\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8073\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8232\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8183\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8085\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8195\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8268\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8110\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8146\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8354\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8317\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8280\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8366\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8354\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8366\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8402\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8329\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8463\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8439\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8427\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8341\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8390\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8256\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8427\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8378\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8280\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8354\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8329\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8256\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8378\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8268\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8537\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8256\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8280\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8293\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8305\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8366\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8427\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8427\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8146\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8390\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8427\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8378\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8390\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8451\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8354\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8354\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8439\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8256\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8232\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8244\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8256\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8488\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8427\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8415\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8378\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8415\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8378\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8451\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8415\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8573\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8415\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8366\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8378\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8415\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8220\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8134\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8159\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8476\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8439\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8207\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8427\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8524\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8500\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8244\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8000\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8134\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8293\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8671\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8415\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8488\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8378\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8354\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8451\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8378\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8329\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8317\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8476\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8354\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8366\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8305\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8341\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8220\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8305\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8390\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8171\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8244\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8354\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8354\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8488\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8415\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8451\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8280\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8305\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8256\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8378\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8354\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8378\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8366\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8427\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8415\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8476\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8463\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8585\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8561\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8341\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8451\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8476\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8341\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8341\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8402\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8549\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8439\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8378\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8439\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8415\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8256\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8500\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8293\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8232\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8354\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8268\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8463\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8427\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8463\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8451\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8183\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8244\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8293\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8524\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8439\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8329\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8098\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8500\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8463\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8317\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8561\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8317\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8427\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8244\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8354\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8366\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8329\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8293\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8549\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8354\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8354\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8427\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8524\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8183\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8415\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8415\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8280\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8439\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8390\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8427\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8500\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8463\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8488\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8427\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8232\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8415\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8427\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8439\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8244\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8537\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8439\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8451\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8476\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8451\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8366\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8354\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8500\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8390\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8524\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8451\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8476\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8451\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8366\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8439\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8537\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8451\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8378\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8366\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8415\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8390\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8366\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8317\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8378\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8207\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8390\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8402\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8110\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8073\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8415\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8366\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8439\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8427\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8402\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8512\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8159\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8207\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8573\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8341\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8402\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8415\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8232\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8268\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8354\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8402\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8451\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8439\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8561\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8268\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8561\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8439\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8341\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8378\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8293\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8634\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8415\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8232\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8390\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8378\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8476\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8415\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8439\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8232\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8463\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8390\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8378\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8366\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8378\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8451\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8366\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8402\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8512\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8220\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8329\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8183\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8390\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8305\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8341\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8439\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8451\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8512\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8378\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8549\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8280\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8415\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a90d429ba0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c844af4f00d40c4cce4c4e5a9a01c9a892e9533d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "7e95c4946c0103225663862f43f31c41ed5aa2b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "66d9268e3f87b5a98066196eaa39363218a20015"
   },
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in Y_pred_nn]\n",
    "\n",
    "Y_pred_nn = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "888d79632c3191c2d11c1ec3da8dc750c9d95424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Neural Network is: 84.39 %\n"
     ]
    }
   ],
   "source": [
    "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")\n",
    "\n",
    "#Note: Accuracy of 85% can be achieved on the test set, by setting epochs=2000, and number of nodes = 11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 1s 1ms/step - loss: 3.4733 - accuracy: 0.5390\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.2879 - accuracy: 0.5951\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.1119 - accuracy: 0.6085\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.6146\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0046 - accuracy: 0.6146\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.6146\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8133 - accuracy: 0.6110\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6476\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6598\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6512\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7061\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6744\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6915\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6976\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7085\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6866\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7061\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.6976\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7012\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.6988\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7195\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7232\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7195\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7171\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7207\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7256\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7293\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7378\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7378\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7256\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7415\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7463\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7378\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7537\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7512\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7622\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7622\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7585\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7598\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7573\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7598\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7659\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7720\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7780\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7659\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7805\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7744\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7841\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7878\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7878\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7878\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7841\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7841\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7902\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7939\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7902\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7902\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7939\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8134\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8171\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8049\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8159\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7951\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8037\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8134\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8061\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8024\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8098\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8085\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8220\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8171\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8061\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8061\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8244\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8122\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8073\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8159\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8232\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8244\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8244\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8073\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8171\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8220\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8280\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8232\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8317\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8220\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8366\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8341\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8305\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8354\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8268\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8256\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8415\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8317\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8329\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8354\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.8207\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8427\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8427\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8378\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8427\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8378\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8341\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8268\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8317\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8524\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8366\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8476\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8524\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8378\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8293\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8354\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8390\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.8317\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8390\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8366\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8451\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8451\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8439\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8305\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8439\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8451\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8378\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8500\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8488\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8537\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8488\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8317\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8402\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8451\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8476\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8439\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8402\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8659\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8463\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8524\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8439\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8415\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8488\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8476\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8500\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8415\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8220\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8524\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8427\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8524\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8585\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8524\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8390\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8415\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8537\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8500\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8488\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8549\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8378\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8598\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8512\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8561\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8549\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8463\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8561\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8488\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8366\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8488\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8549\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8500\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8537\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8610\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8488\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8451\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8415\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8439\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8561\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8549\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8561\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8366\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8573\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8463\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8610\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8500\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8561\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8549\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8585\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8500\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.8488\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8537\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8415\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8610\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8585\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8451\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8585\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8524\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8415\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8354\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8329\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8561\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8524\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8488\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8415\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8500\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8476\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8549\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8463\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8500\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8293\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8366\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8537\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8610\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8415\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8573\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8512\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8549\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8463\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8549\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8476\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8183\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8537\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8537\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8415\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8634\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8683\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8610\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8549\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8585\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8683\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8549\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8488\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8549\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8610\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8354\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8427\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8646\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8573\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8573\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8549\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8537\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8598\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8537\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8512\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8512\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8537\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8524\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8549\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8561\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8415\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8585\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8671\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8415\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8488\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8610\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8476\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8561\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8415\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8659\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8512\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8537\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8622\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8549\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8646\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8573\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8634\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8744\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8598\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8439\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8659\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8634\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8512\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8610\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8585\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8573\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8488\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8537\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8585\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8524\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8622\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8622\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8415\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8427\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8537\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8634\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8500\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8622\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8634\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8634\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8610\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8598\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8537\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8537\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8476\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8622\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8671\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8646\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8659\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8573\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8707\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8573\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8512\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8512\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a90e6702e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(11,activation='relu',input_dim=13))\n",
    "model1.add(Dense(5,activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model1.fit(X_train,Y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nn_1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded1 = [round(x[0]) for x in Y_pred_nn_1]\n",
    "\n",
    "Y_pred_nn_1 = rounded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Neural Network is: 84.39 %\n"
     ]
    }
   ],
   "source": [
    "score_nn_1 = round(accuracy_score(Y_pred_nn_1,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn_1)+\" %\")\n",
    "\n",
    "#Note: Accuracy of 85% can be achieved on the test set, by setting epochs=2000, and number of nodes = 11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c634cd922d716d350f6db0244772260cc598dec4"
   },
   "source": [
    "## Output final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "101daa51242624c49bb8b3198d9d2c9f8f1c596e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 86.34 %\n",
      "The accuracy score achieved using Neural Network is: 84.39 %\n",
      "The accuracy score achieved using Neural Network_1 is: 84.39 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_lr,score_nn,score_nn_1]\n",
    "algorithms = [\"Logistic Regression\",\"Neural Network\",\"Neural Network_1\"]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
